{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Washington DC Housing Market Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Data\n",
    "\n",
    "\n",
    "This analysis uses DC housing market data from Refin for condos and macroeconomic data from Fred with the time periods between February 2010 and October 2019. Housing data includes data for prices (median sale price, percentage of homes sold above list price, percentage of homes that had price drop, etc.), inventory (number of homes on market, new listings, months of supply, etc.), and sales (number of homes sold, median days on market, etc.). For economic data, refer to [readme](https://github.com/iuniorhsiung/mod4_project_DC_housing_price/blob/master/data/readme.md). Most of our economic data are regional data in DC or DC-VA-MD-WV regions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "\n",
    "In order to price the condos in Washington DC, we perform time-series linear regression with DC housing statistics and regional macroeconomic variables. For the theory behind it, please refer to [this](https://www.reed.edu/economics/parker/312/tschapters/S13_Ch_2.pdf).\n",
    "\n",
    "\n",
    "### Data Analysis\n",
    "\n",
    "After collecting our data, based on the model assumptions, we need to comfirm if both independent and dependent variables are stationary. In addition, we check if the autocorrelation for these variables is zero. There are four parts are performed: (1) time series plots, (2) acf/pacf plots, (3) [stationary test](https://en.wikipedia.org/wiki/KPSS_test) and (4) [autocorrelation test](https://en.wikipedia.org/wiki/Durbin%E2%80%93Watson_statistic). For the positive variables, we will also use log-transformation for them. In addition, based on the dataset, we construct a 1st difference transfomation for all features as our final dataset.   \n",
    "\n",
    "Note that our data time frame ranges from Feburary 2010 to October 2019. It includes 117 monthly data. \n",
    "\n",
    "\n",
    "### Feature Selection \n",
    "\n",
    "Based on the data analysis section, we pre-selected a pool of our features (independent variables). In this section, we perform (1) [Forward-Backward stepwise regression](https://en.wikipedia.org/wiki/Stepwise_regression) and (2) [KBest selection](https://www.kaggle.com/jepsds/feature-selection-using-selectkbest)\n",
    "\n",
    "###  Model Fit\n",
    "\n",
    "We perform a time-series regression based on the selected features in Feature Selection section. Note that we will check if the sign for each feature comes with business rationale. For our dataset, we divide it into train dataset/In-Time Sample and test dataset/Out-of-Time Sample (OOT Sample). For the time-series modeling practice, we use the first 100 monthly data as In-Time sample and last 17 monthly data as OOT sample. \n",
    "\n",
    "\n",
    "### Cross Validation\n",
    "\n",
    "We will work on cross validaiton on OOT sample since there is a time effect in our housing dataset. \n",
    "\n",
    "\n",
    "### Model Performance\n",
    "\n",
    "We evaluate our model performance based on the following two metrics:\n",
    "\n",
    "- Mean Absolute Error (MAE): Based on our project goal, MAE estimates the dollar impact for the model residual. For example, it is 700 dollars in error if MAE is 700. Please refer to [MAE].(https://en.wikipedia.org/wiki/Mean_absolute_error)\n",
    "\n",
    "- Mean Absolute Percentage Error (MAPE): Similar to MAE, MAPE esitmates the percentage impact in housing price. For example, the model shows about 2.5% error if MAPE is .0249. Please refer to [MAPE].(https://en.wikipedia.org/wiki/Mean_absolute_percentage_error)\n",
    "\n",
    "### Residual Analysis\n",
    "\n",
    "Based on the assumptions for [time series linear regression](https://www.reed.edu/economics/parker/312/tschapters/S13_Ch_2.pdf) in Methodology section, we perform the following analyses:\n",
    "\n",
    "- Stationary test: To ensure the constant mean exists for model residual.\n",
    "\n",
    "- Homoscedastic test: To ensure the constant variance for model residual. We perform both [Breusch–Pagan test](https://en.wikipedia.org/wiki/Breusch%E2%80%93Pagan_test) and [Goldfeld–Quandt test](https://en.wikipedia.org/wiki/Goldfeld%E2%80%93Quandt_test). \n",
    "\n",
    "- Autocorrelation test: To ensure there is no strong autocorrelation in moder residual (or autocorrelation is zero). \n",
    "\n",
    "In addition, we study the distribution of the model residuals with the following analyses:\n",
    "\n",
    "- Normality test: We will perform both normality test based on [D’Agostino and Pearson’s test](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.normaltest.html) and [KPSS test](https://en.wikipedia.org/wiki/KPSS_test).\n",
    "\n",
    "- Q-Q plot\n",
    "\n",
    "\n",
    "\n",
    "### Rationale for the current approach:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import\n",
    "\n",
    "Here, we import all code and libraries based on the \"Data_cleaning_house_price.ipynb\" and \"ConstructingDataFrame.ipynb\". This takes care of all data imports and data format for the final modeling use including transformed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../python_folder/python_files/importlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation\n",
    "\n",
    "We perform two types of transformation: log, first difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../python_folder/python_files/transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data visualization\n",
    "\n",
    "In Data Analysis section, time series plots and ACF/PACF plots are used to check the data visually. Please refer to [DC_house_price_EDA_JC.ipynb](https://github.com/iuniorhsiung/mod4_project_DC_housing_price/tree/master/master_notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Test\n",
    "\n",
    "We performed the following hypothesis tests on our housing/economic dataframe:\n",
    "\n",
    "- KPSS test for stationarity \n",
    "- ADF test for stationarity\n",
    "- Durbin–Watson for autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for Hypothesis Test\n",
    "# %load ../python_folder/python_files/test_matrix_kpss_dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run hypothesis tests for df with log transformation\n",
    "test_matrix = hypo_test(col_name = col_name, data = df)\n",
    "# Run hypothesis tests for df1 with 1st diff transformation\n",
    "test_matrix1 = hypo_test(col_name = col_name1, data = df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for determine sig level and index\n",
    "# %load ../python_folder/python_files/Test_p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### df dataset\n",
    "Original Data with log transformation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_p_value(p = .05, name = 'adftest')\n",
    "test_p_value(p = .05, name = 'kpsstest')\n",
    "test_p_value(p = .05, name = 'ljtest')\n",
    "test_matrix\n",
    "# Save the final testing results in data folder\n",
    "test_matrix.to_csv('../data/TM_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all features are stationary based on both KPSS and adf tests\n",
    "index_adf = test_matrix['index_adftest'] == 1\n",
    "index_kpss = test_matrix['index_kpsstest'] == 0\n",
    "index_lj = test_matrix['index_ljtest'] == 0\n",
    "index_dw1 = test_matrix['stat_dw'] >= .9\n",
    "index_dw2 = test_matrix['stat_dw'] <= 3.1 \n",
    "test_col = list(test_matrix[index_adf & index_kpss][\"Features\"])\n",
    "test_col\n",
    "test_col.remove('Median Sale Price MoM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### df1 dataset\n",
    "Data with 1st diff transformation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_p_value(p = .05, name = 'adftest', data = test_matrix1)\n",
    "test_p_value(p = .05, name = 'kpsstest', data = test_matrix1)\n",
    "test_p_value(p = .05, name = 'ljtest', data = test_matrix1)\n",
    "test_matrix1\n",
    "test_matrix1.to_csv('../data/TM_test_1diff.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all features are stationary based on both KPSS and adf tests\n",
    "index_kpss = test_matrix1['index_kpsstest'] == 0\n",
    "index_lj = test_matrix1['index_ljtest'] == 0\n",
    "index_dw1 = test_matrix1['stat_dw'] >= .9 \n",
    "index_dw2 = test_matrix1['stat_dw'] <= 3.1 \n",
    "index_adf = test_matrix1['index_ljtest'] == 1\n",
    "test_col1 = list(test_matrix1[index_adf & index_kpss & index_dw1 & index_dw2][\"Features\"])\n",
    "test_col1\n",
    "test_col1.remove('Median Sale Price_1diff')\n",
    "test_col1.remove('Median Sale Price_log_1diff')\n",
    "test_col1.remove('Median Sale Price MoM_1diff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split In-Time and Out-of-Time samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = pd.concat([df[test_col][1:100], df1[test_col1][0:99]], axis=1)\n",
    "test_x = pd.concat([df[test_col][100:117], df1[test_col1][99:116]], axis=1)\n",
    "train_y = df1[\"Median Sale Price_1diff\"][0:99]\n",
    "test_y = df1[\"Median Sale Price_1diff\"][99:116]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection: Forward/Backward stepwise regression and KBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for Stepwise Regression\n",
    "# %load ../python_folder/python_files/ForwardBackwardStepwiseRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = stepwise_selection(train_x, train_y, threshold_in = 0.1, threshold_out = 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('resulting features:')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../python_folder/python_files/KBest\n",
    "# Feature selection using KBest with f_regreesion\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html?highlight=selectkbest#sklearn.feature_selection.SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_kbest = list(featureScores.nlargest(10,'Score')['Specs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series Regression\n",
    "Four variables are selected and three are from stepwise regression. We added one variable: WDXRSA (S&P/Case-Shiller DC-Washington Home Price Index) based on business rationale  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_x = train_x[['Days on Market_1diff', 'US_UR_1diff', 'New Listings MoM_1diff', 'WDXRSA_1diff']]\n",
    "train_X = sm.add_constant(sel_x)\n",
    "mod = sm.OLS(train_y, train_X, hasconst= True)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multicollinearity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif = [variance_inflation_factor(sel_x.values, i) for i in range(sel_x.shape[1])]\n",
    "list(zip(['Days on Market_1diff', 'US_UR_1diff', 'New Listings MoM_1diff', 'WDXRSA_1diff'], vif))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normality for the residual term: KS test and QQ plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kstest\n",
    "from scipy.stats import stats\n",
    "#residual = mlr.predict(X) - Y\n",
    "residual = res.resid\n",
    "kstest(residual, \"norm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sm.qqplot(residual, line = 'r')\n",
    "plt.show()\n",
    "fig.savefig(\"../data_visualization/Q-Q Plot for In-Sample Fit.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../python_folder/python_files/reverse_1st_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In Time Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = first_diff(data = res.predict(train_X), ini_value = df['Median Sale Price'][0])\n",
    "error = df[\"Median Sale Price\"][1:100] - pred_y[1:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Performance Metrics for In Time Sample\n",
    "MAE: Around 10591.33 dollar impact \n",
    "    \n",
    "MAPE: Around 4.02% price difference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAE\n",
    "np.mean(abs(error))\n",
    "#MAPE\n",
    "np.mean(abs(error)/df[\"Median Sale Price\"][1:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OOT Sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../python_folder/python_files/OOT_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Performance Metrics for OOT Time Sample\n",
    "MAE: Around 7882.99 dollar impact \n",
    "    \n",
    "MAPE: Around 2.61% price difference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAE\n",
    "np.mean((abs(error_oot)))\n",
    "#MAPE\n",
    "np.mean((abs(error_oot))/df[\"Median Sale Price\"][100:117])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset for time series plot with Actual, In Time,and OOT samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../python_folder/python_files/data_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot for Model Performance\n",
    "We should the actual median house price in Blue, In Time Model Performance in Orange dash line, and OOT Model Performance in Green dot line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_data = [predict_m.loc[:, \"Median Sale Price\"], predict_m.loc[:\"5 31 2018\", \"In Time\"], predict_m.loc[\"6 1 2018\":, \"OOT Time\"]]\n",
    "ax = sns.lineplot(data=list_data, legend=\"full\")\n",
    "plt.title(\"Prediction House Price\", fontsize = 40)\n",
    "plt.xlabel(\"Month\", fontsize = 30)\n",
    "plt.ylabel(\"Condo Price\", fontsize = 30)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
